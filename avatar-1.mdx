---
title: "Avatar"
---

Tess AI’s Avatar tool lets you create videos with a digital presenter who “speaks” a script you provide, with lip sync. This enables professional-looking content without a camera, studio, in-person recording, or traditional editing — ideal for scale and standardization.

In this process, the AI animates the avatar, generates or uses the audio, syncs lip movements with speech, and renders the final video for download.

### **Models available in Tess**

To enable it, just find the Avatar option in the tools button. There you’ll find models like HeyGen, Omni Human, and Wan.

Each option tends to have different configuration and performance (avatar style, realism, expressiveness, lip sync quality, language/voice options, etc.).

<Card icon="1" title="Heygen">
  \
  It is focused on creating avatar videos mainly for commercial use.

  <u>Strengths:</u> Very easy and fast: interface, templates, teleprompter, subtitles, translations/dubbing, ready-made flows. Consistent quality for “presenter talking to the camera”.

  <u>Typical limitations:</u> Less “creative freedom” in the model, since you operate within what the platform offers. Less flexible for complex scenes (full body in motion, interaction with the environment, long acting).

  You stay “inside the editor” and the platform’s options (less low-level control).

  <Frame>
    ![Captura De Tela 2026 02 13 Às 14 45 17](/images/CapturadeTela2026-02-13às14.45.17.png)
  </Frame>
  <Info>
    **When it makes the most sense:** marketing videos, onboarding, tutorials, internal updates, etc.
  </Info>
  See more in chat: [Access conversation](https://tess.im/published-chats/d83fe0c4-7aa2-4823-b348-e57bccdfbe58)
</Card>

<Card icon="2" title="Omni Human">
  \
  Its focus is movement/expression quality and generalization to different identities/poses

  - It can accept: audio + reference image/video → animation/lipsync
  - Or text/conditions + reference → generated/animated human

  <u>Strengths:</u> Potentially better realism in expressions, face consistency, and movement (depending on the version). More freedom if you need to move beyond the “standard presenter” and into acting/movement/styles.

  <u>Limitations:</u> Higher chance of “variance” and need for adjustments (seed, parameters, post-processing).

  <Frame>
    ![Image](/images/image-15.png)
  </Frame>
  <Info>
    **When it makes the most sense:** technical team, R&D, or when you need visual control beyond the corporate standard.
  </Info>
  See more in chat: [Access conversation](https://tess.im/published-chats/36fc7b90-48c7-4078-8bfc-db1a482309ef)
</Card>

<Card icon="3" title="Wan">
  \
  “Wan” has a family of models; in this tool we provide the sync and animation one.

  - Image → video (animate an image)
  - Sometimes: audio + image → talking head

  <u>Strengths:</u> Very good for creating scenes and videos based on images and also from scratch.

  <u>Limitations:</u> In some cases and languages, audio-to-image sync may not keep the mouth perfect. Or even identity consistency (the face staying the same throughout the video) can be harder than on platforms focused on avatars.

  <Frame>
    ![Image](/images/image-14.png)
  </Frame>
  <Info>
    **When it makes the most sense:** creating full/stylized videos, more “cinematic” ads, scenes with environments; or when the avatar is just part of the video.
  </Info>
  See more in chat: [Access conversation](https://tess.im/published-chats/5544bc98-1875-4249-8644-ddd93f1125a5)
</Card>

**When to use (ideal cases)**

- onboarding modules
- product and process trainings
- internal policies and standardized announcements
- short announcement videos
- feature presentations
- welcome messages and “product tours” with consistent identity
- team/project updates
- leadership communications (with standardization and speed)
- short educational videos (Reels/TikTok)
- weekly series with the same visual identity

<Tip>
  Tip:

  If you want, you can combine Avatar + Speech (Narration) for full control, especially if you want maximum voice consistency (tone, rhythm, timbre).
</Tip>

**How to write scripts that sound natural in an avatar**

- Write “to be spoken”, not like an article
- Use short, direct sentences
- Avoid long paragraphs
- Add natural pauses with punctuation
- For acronyms, prefer writing them out in full the first time (e.g., “Customer Success” before “CS”)
- If there are technical terms, include one sentence of context to reduce “robotic reading”

<Warning>
  **Credits usage and generation time**

  Avatar videos tend to consume more credits than text and simple narration, because they involve rendering. They can also take a bit longer to be ready, especially for long videos or higher-quality settings.
</Warning>

If you need anything, you can reach our support team at: [support@tess.im](mailto:support@tess.im).
