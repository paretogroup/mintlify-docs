---
title: "Tess 6.1"
---

Tess 6.1 offers an agentic orchestration experience of different models for the execution of a single complex task. You give your prompt and, instead of using just one LLM to respond to your request, this model activates a Multi-LLM architecture in a single request: multiple models work in a chain, collaboratively, reviewing and refining each other's work before you receive the final response.

In practice: you ask a question as you always do. Behind the scenes, different AI models discuss, refine, and consolidate a joint response â€” and you receive the result ready, in a single message.

### **What is Tess 6.1**

Tess 6.1 is an orchestrated model of robust collaboration between LLMs, designed to:

- combine the strengths of different models
- reduce errors and contradictions in complex tasks
- deliver more consistent, structured, and "thought-through" responses with a single prompt

When you select it in the chat, Tess:

- activates the Multi-LLM mechanism for that message
- coordinates collaboration between multiple state-of-the-art models
- returns a single, already consolidated response, also presenting the entire chain of reasoning from each model throughout the delivery flow

When to use Tess 6.1 (and when you don't need to)

<Columns cols={2}>
  <Card title="Use Tess 6.1 when">
    - The topic is complex or strategic
    - You need "thought-through" and well-structured responses
    - There are multiple reasoning steps involved
  </Card>
  <Card title="Prefer other LLMs">
    - The task is quick and simple
    - The focus is cost/speed, not depth
    - Exploring ideas without rigor
  </Card>
</Columns>

<Note>
  **Important**

  - Even though it is Multi-Model, this does not replace human validation on critical topics (legal, financial, medical, high-impact decisions).
  - It will naturally take a few extra seconds to generate the final response, due to the nature of the model.
  - It is not the best option for quick and low-cost tasks (short responses, minor adjustments).
  - Because it uses multiple models, any differences in "style" between them are harmonized, but may appear in very extreme tone/style requests; if this occurs, be very specific about the desired tone.
</Note>
