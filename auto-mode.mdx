---
title: "Auto Mode"
---

Let Tess automatically choose the best AI model for each conversation, without needing to be an LLM expert.

### **What is Auto Mode in Tess Chat?**

It's the technology that allows Tess to choose which LLM to use to respond to your request at the time of the query. Instead of having to manually decide which model to use for each chat, Tess evaluates the type of message and selects the most suitable model at that moment.

This is made possible through a sophisticated routing algorithm developed by Tess to choose the best model according to several variables: response quality (performance), speed, cost, and the complexity of the model and request. This is the safest option for those who want good responses without needing to understand models.

<Frame>
  ![Tessdocs Modomax](/images/tessdocs-modomax.png)
</Frame>

### **Why does it matter?**

- Ideal for non-specialists: you don't need to know technical details about AI.
- Strong overall performance: Tess chooses an appropriate model for most cases.
- Collaboration between models: with each query, a new model can be called and collaborate with the previous model's response.

### **Quick start**

<Steps>
  <Step title="Open the chat">
    Start a new conversation or reopen one from your history
  </Step>
  <Step title="Enable the Auto option">
    If it's not already selected, find the LLMs control and enable the "Auto" option
  </Step>
  <Step title="Start or continue your conversation">
    Send your typical messages (support, sales, internal). Observe the quality and response time.

    If in any specific case you want to test another model, temporarily disable Auto, manually select any LLM from the list, and compare the results.

    Switching between models is the key to Multi-LLM usage in a single chat!
  </Step>
</Steps>

<Tip>
  **Tips:**

  - Use Auto as the default for teams that aren't familiar with AI.
  - Choose a specific LLM when there's a clear reason to do so, stepping out of Auto Mode due to quality, cost, or compliance requirements, for example.
  - Test periodically: compare responses with Auto on and with a specific AI model to ensure the balance continues to make sense for your context.
</Tip>
